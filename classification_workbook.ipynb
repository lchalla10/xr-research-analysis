{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1b7gmvcW_f1"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import umap\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, minmax_scale\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from umap import UMAP  # Requires: pip install umap-learn\n",
        "\n",
        "warnings.simplefilter(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Global Variable Definitions\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The \"root\" folder that holds all the experiment data; must follow a strict folder structure.\n",
        "ROOT = \"data\"\n",
        "\n",
        "# The experiment type folder to look into, if each experiment has a \"hand\" and a \"controller\" folder.\n",
        "FOLDER = \"controller\"\n",
        "\n",
        "# Number of participants and experiments to index; TODO: Detect this automatically.\n",
        "PARTICIPANTS = 4\n",
        "EXPERIMENTS = 10\n",
        "\n",
        "# The list of files to analyze.\n",
        "FILE_LIST = [\n",
        "        'Ball_1.csv', 'Ball2_1.csv', 'Ball3_1.csv', 'Ball4_1.csv', 'Ball5_1.csv',\n",
        "        'Ball6_1.csv', 'Ball7_1.csv', 'Ball8_1.csv', 'Ball9_1.csv', 'Ball10_1.csv',\n",
        "        'CubeMetal_1.csv', 'CubeNormal_1.csv', 'CubeWood_1.csv',\n",
        "        'Cup_1.csv', 'Cup2_1.csv', 'Hammer_1.csv', 'Mallet_1.csv'\n",
        "    ]\n",
        "\n",
        "# The test size for the test/training data ratio. Standard is 80% training data, 20% test data.\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "# Various features arrays categorized by the data they hold. \n",
        "imu_cols = [\"imu_pos_x\", \"imu_pos_y\", \"imu_pos_z\", \"imu_rot_x\", \"imu_rot_y\", \"imu_rot_z\"]\n",
        "object_cols = ['lv_x', 'lv_y', 'lv_z', 'av_x', 'av_y', 'av_z', 'pos_x', 'pos_y', 'pos_z']\n",
        "hands_cols = [\n",
        "    # 'lh_pos_x', 'lh_pos_y', 'lh_pos_z', 'lh_rot_x', 'lh_rot_y', 'lh_rot_z',\n",
        "    'rh_pos_x', 'rh_pos_y', 'rh_pos_z', 'rh_rot_x', 'rh_rot_y', 'rh_rot_z'\n",
        "]\n",
        "fingers_cols = [\n",
        "    # 'lh_thumb_x', 'lh_thumb_y', 'lh_thumb_z',\n",
        "    # 'lh_index_x', 'lh_index_y', 'lh_index_z',\n",
        "    # 'lh_middle_x', 'lh_middle_y', 'lh_middle_z',\n",
        "    # 'lh_ring_x', 'lh_ring_y', 'lh_ring_z',\n",
        "    # 'lh_little_x', 'lh_little_y', 'lh_little_z',\n",
        "    'rh_thumb_x', 'rh_thumb_y', 'rh_thumb_z',\n",
        "    'rh_index_x', 'rh_index_y', 'rh_index_z',\n",
        "    'rh_middle_x', 'rh_middle_y', 'rh_middle_z',\n",
        "    'rh_ring_x', 'rh_ring_y', 'rh_ring_z',\n",
        "    'rh_little_x', 'rh_little_y', 'rh_little_z'\n",
        "]\n",
        "\n",
        "# This is the important variable that will be used by the training model.\n",
        "# Put any physical features you want to include here.\n",
        "FEATURES_COLS = [object_cols, hands_cols, fingers_cols, imu_cols]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Extraction\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_features(df):\n",
        "    features = []\n",
        "    for col_group in FEATURES_COLS:\n",
        "        group_data = df[col_group]\n",
        "        stats = [\n",
        "            group_data.mean(),\n",
        "            group_data.std(),\n",
        "            group_data.max(),\n",
        "            group_data.min(),\n",
        "            group_data.quantile(0.25),\n",
        "            group_data.quantile(0.75),\n",
        "            group_data.skew(),\n",
        "            group_data.kurtosis(),\n",
        "        ]\n",
        "        features.extend([stat.values for stat in stats])\n",
        "    return np.concatenate(features)\n",
        "\n",
        "def extract_temporal_features(df):\n",
        "    features = []\n",
        "    for col in df.columns:\n",
        "        values = df[col].values\n",
        "\n",
        "        # First-order difference (velocity changes)\n",
        "        diff1 = np.diff(values, n=1)\n",
        "        # Second-order difference (jerk)\n",
        "        diff2 = np.diff(values, n=2)\n",
        "\n",
        "        # Autocorrelation (lag=1)\n",
        "        autocorr = np.corrcoef(values[:-1], values[1:])[0, 1] if len(values) > 1 else 0\n",
        "\n",
        "        # Store new features\n",
        "        features.extend([\n",
        "            np.mean(diff1), np.std(diff1), np.max(diff1), np.min(diff1),\n",
        "            np.mean(diff2), np.std(diff2), np.max(diff2), np.min(diff2),\n",
        "            autocorr\n",
        "        ])\n",
        "    return np.array(features)\n",
        "\n",
        "def load_data(base_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "    successful_files = 0\n",
        "    failed_files = 0\n",
        "    missing_files = 0\n",
        "\n",
        "    for person in range(1, PARTICIPANTS+1):\n",
        "        for folder in range(1, EXPERIMENTS+1):\n",
        "            for file_name in FILE_LIST:\n",
        "                file_path = os.path.join(base_path, str(person), FOLDER, str(folder), file_name)\n",
        "                if os.path.exists(file_path):\n",
        "                    df = read_csv_file(file_path)\n",
        "                    if df is not None and not df.empty:\n",
        "                        try:\n",
        "                            features = extract_features(df)\n",
        "                            data.append(features)\n",
        "                            labels.append(person - 1)\n",
        "                            successful_files += 1\n",
        "                            #print(f\"Successfully processed: {file_path}\")\n",
        "                        except Exception as e:\n",
        "                            failed_files += 1\n",
        "                            print(f\"Error processing {file_path}: {str(e)}\")\n",
        "                else:\n",
        "                    missing_files += 1\n",
        "                    print(f\"File does not exist: {file_path}\")\n",
        "\n",
        "    print(f\"\\nProcessing Summary:\")\n",
        "    print(f\"Successful files: {successful_files}\")\n",
        "    print(f\"Failed files: {failed_files}\")\n",
        "    print(f\"Missing files: {missing_files}\")\n",
        "    print(f\"Total files checked: {successful_files + failed_files + missing_files}\")\n",
        "\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "def read_csv_file(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            header_line = file.readline().strip()\n",
        "            columns = [col.strip() for col in header_line.split(',')]\n",
        "        data = pd.read_csv(file_path, skiprows=1, header=None, names=columns)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualization Functions\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_tsne_by_object(X, y, file_list, base_path):\n",
        "    plt.figure(figsize=(25, 15))\n",
        "    n_rows = 3\n",
        "    n_cols = 6\n",
        "    object_types = set()\n",
        "    for file in file_list:\n",
        "        if file.endswith('_1.csv'):\n",
        "            object_name = file.replace('_1.csv', '')\n",
        "            object_types.add(object_name)\n",
        "    plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
        "\n",
        "    for idx, object_name in enumerate(sorted(object_types)):\n",
        "        object_data = []\n",
        "        object_labels = []\n",
        "        for person in range(1, 5):\n",
        "            for folder in range(1, 11):\n",
        "                file_path = os.path.join(base_path, str(person), FOLDER, str(folder), f'{object_name}_1.csv')\n",
        "                if os.path.exists(file_path):\n",
        "                    try:\n",
        "                        df = read_csv_file(file_path)\n",
        "                        if df is not None and not df.empty:\n",
        "                            features = extract_features(df)\n",
        "                            object_data.append(features)\n",
        "                            object_labels.append(person - 1)\n",
        "                    except Exception as e:\n",
        "                        continue\n",
        "\n",
        "        if object_data:\n",
        "            ax = plt.subplot(n_rows, n_cols, idx + 1)\n",
        "            X_obj = np.array(object_data)\n",
        "            y_obj = np.array(object_labels)\n",
        "            # scaler = StandardScaler()\n",
        "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "            X_scaled = scaler.fit_transform(X_obj)\n",
        "            tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(X_scaled)-1))\n",
        "            X_tsne = tsne.fit_transform(X_scaled)\n",
        "            X_tsne = scaler.fit_transform(X_tsne)\n",
        "            for user in range(4):\n",
        "                mask = y_obj == user\n",
        "                plt.scatter(X_tsne[mask, 0], X_tsne[mask, 1],\n",
        "                            c=[colors[user]], label=f'User {user+1}',\n",
        "                            s=80, alpha=0.7, edgecolor='white', linewidth=0.5)\n",
        "\n",
        "            plt.title(object_name, fontsize=12, pad=10, fontweight='bold')\n",
        "            plt.xlabel('t-SNE 1', fontsize=10)\n",
        "            plt.ylabel('t-SNE 2', fontsize=10)\n",
        "            plt.xticks(fontsize=8)\n",
        "            plt.yticks(fontsize=8)\n",
        "            if idx == 0:\n",
        "                plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10, frameon=True)\n",
        "            else:\n",
        "                plt.legend([], [], frameon=False)\n",
        "            plt.grid(True, linestyle='--', alpha=0.3)\n",
        "            ax.spines['top'].set_visible(False)\n",
        "            ax.spines['right'].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def visualize_pca_by_object(X, y, file_list, base_path):\n",
        "    plt.figure(figsize=(25, 15))\n",
        "    n_rows = 3\n",
        "    n_cols = 6\n",
        "    object_types = set()\n",
        "    for file in file_list:\n",
        "        if file.endswith('_1.csv'):\n",
        "            object_name = file.replace('_1.csv', '')\n",
        "            object_types.add(object_name)\n",
        "    plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
        "\n",
        "    for idx, object_name in enumerate(sorted(object_types)):\n",
        "        object_data = []\n",
        "        object_labels = []\n",
        "        for person in range(1, 5):\n",
        "            for folder in range(1, 11):\n",
        "                file_path = os.path.join(base_path, str(person), FOLDER, str(folder), f'{object_name}_1.csv')\n",
        "                if os.path.exists(file_path):\n",
        "                    try:\n",
        "                        df = read_csv_file(file_path)\n",
        "                        if df is not None and not df.empty:\n",
        "                            features = extract_features(df)\n",
        "                            object_data.append(features)\n",
        "                            object_labels.append(person - 1)\n",
        "                    except Exception as e:\n",
        "                        continue\n",
        "\n",
        "        if object_data:\n",
        "            ax = plt.subplot(n_rows, n_cols, idx + 1)\n",
        "            X_obj = np.array(object_data)\n",
        "            y_obj = np.array(object_labels)\n",
        "            # scaler = StandardScaler()\n",
        "            scaler = MinMaxScaler(feature_range=(0,1))\n",
        "            X_scaled = scaler.fit_transform(X_obj)\n",
        "            pca = PCA(n_components=2, random_state=42)\n",
        "            X_pca = pca.fit_transform(X_scaled)\n",
        "            X_pca = scaler.fit_transform(X_pca)\n",
        "            for user in range(4):\n",
        "                mask = y_obj == user\n",
        "                plt.scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
        "                            c=[colors[user]], label=f'User {user+1}',\n",
        "                            s=80, alpha=0.7, edgecolor='white', linewidth=0.5)\n",
        "\n",
        "            plt.title(object_name, fontsize=12, pad=10, fontweight='bold')\n",
        "            plt.xlabel('PCA 1', fontsize=10)\n",
        "            plt.ylabel('PCA 2', fontsize=10)\n",
        "            plt.xticks(fontsize=8)\n",
        "            plt.yticks(fontsize=8)\n",
        "            if idx == 0:\n",
        "                plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10, frameon=True)\n",
        "            else:\n",
        "                plt.legend([], [], frameon=False)\n",
        "            plt.grid(True, linestyle='--', alpha=0.3)\n",
        "            ax.spines['top'].set_visible(False)\n",
        "            ax.spines['right'].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def visualize_umap_by_object(X, y, file_list, base_path):\n",
        "    plt.figure(figsize=(25, 15))\n",
        "    n_rows, n_cols = 3, 6\n",
        "    object_types = {file.replace('_1.csv', '') for file in file_list if file.endswith('_1.csv')}\n",
        "\n",
        "    plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
        "\n",
        "    for idx, object_name in enumerate(sorted(object_types)):\n",
        "        object_data, object_labels = [], []\n",
        "\n",
        "        for person in range(1, 5):\n",
        "            for folder in range(1, 11):\n",
        "                file_path = os.path.join(base_path, str(person), FOLDER, str(folder), f'{object_name}_1.csv')\n",
        "\n",
        "                if os.path.exists(file_path):\n",
        "                    try:\n",
        "                        df = read_csv_file(file_path)\n",
        "                        if df is not None and not df.empty:\n",
        "                            features = extract_features(df)\n",
        "                            object_data.append(features)\n",
        "                            object_labels.append(person - 1)  # Assign labels (0-3)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing {file_path}: {e}\")\n",
        "                        continue\n",
        "\n",
        "        if object_data:\n",
        "            ax = plt.subplot(n_rows, n_cols, idx + 1)\n",
        "            X_obj = np.array(object_data)\n",
        "            y_obj = np.array(object_labels)\n",
        "\n",
        "            if X_obj.shape[0] != len(y_obj):\n",
        "                print(f\"Skipping {object_name}: Feature and label size mismatch.\")\n",
        "                continue\n",
        "\n",
        "            # scaler = StandardScaler()\n",
        "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "            X_scaled = scaler.fit_transform(X_obj)\n",
        "\n",
        "            umap_model = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.02, random_state=42)\n",
        "            X_umap = umap_model.fit_transform(X_scaled)\n",
        "            X_umap = scaler.fit_transform(X_umap)\n",
        "\n",
        "            if X_umap.shape[0] != len(y_obj):\n",
        "                print(f\"Skipping {object_name}: UMAP output and labels size mismatch.\")\n",
        "                continue  # Skip this object if still mismatched\n",
        "\n",
        "            for user in np.unique(y_obj):  # Dynamically get unique users\n",
        "                mask = (y_obj == user)\n",
        "\n",
        "                plt.scatter(\n",
        "                    X_umap[mask, 0], X_umap[mask, 1],\n",
        "                    c=[colors[user % len(colors)]], label=f'User {user+1}',\n",
        "                    s=80, alpha=0.7, edgecolor='white', linewidth=0.5\n",
        "                )\n",
        "\n",
        "            plt.title(object_name, fontsize=12, pad=10, fontweight='bold')\n",
        "            plt.xlabel('UMAP 1', fontsize=10)\n",
        "            plt.ylabel('UMAP 2', fontsize=10)\n",
        "            plt.xticks(fontsize=8)\n",
        "            plt.yticks(fontsize=8)\n",
        "\n",
        "            if idx == 0:\n",
        "                plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10, frameon=True)\n",
        "            else:\n",
        "                plt.legend([], [], frameon=False)\n",
        "\n",
        "            plt.grid(True, linestyle='--', alpha=0.3)\n",
        "            ax.spines['top'].set_visible(False)\n",
        "            ax.spines['right'].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training and Classification\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d0QmeoXlbq8o",
        "outputId": "383acddb-8986-4651-ca13-5362b577875a"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_model(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_classifier.fit(X_train_scaled, y_train)\n",
        "    y_pred = rf_classifier.predict(X_test_scaled)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "    return rf_classifier, scaler\n",
        "\n",
        "def print_classification_results(X, y, object_name=None):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y,\n",
        "        test_size=TEST_SIZE,\n",
        "        random_state=42,\n",
        "        stratify=y\n",
        "    )\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_classifier.fit(X_train_scaled, y_train)\n",
        "    y_pred = rf_classifier.predict(X_test_scaled)\n",
        "\n",
        "    print(\"\\nData Distribution:\")\n",
        "    unique, counts = np.unique(y, return_counts=True)\n",
        "    print(\"Total samples per user:\", dict(zip([f\"User {i+1}\" for i in unique], counts)))\n",
        "\n",
        "    unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
        "    print(\"Test set samples per user:\", dict(zip([f\"User {i+1}\" for i in unique_test], counts_test)))\n",
        "\n",
        "    title = f\"\\nClassification Results for {object_name}\" if object_name else \"\\nOverall Classification Results\"\n",
        "    print(title)\n",
        "    print(\"-\" * len(title))\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"True\\\\Pred |  User1  User2  User3  User4\")\n",
        "    print(\"-\" * 40)\n",
        "    for i, row in enumerate(cm):\n",
        "        print(f\"User {i+1}    | {str(row).center(20)}\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    return rf_classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    base_path = os.path.join(os.getcwd(), ROOT)\n",
        "    print(f\"Loading data from: {base_path}\")\n",
        "\n",
        "    # Load data and perform overall classification\n",
        "    X, y = load_data(base_path)\n",
        "    print_classification_results(X, y)\n",
        "\n",
        "    # Per-object classification results\n",
        "    object_types = set()\n",
        "    for file in FILE_LIST:\n",
        "        if file.endswith('_1.csv'):\n",
        "            object_name = file.replace('_1.csv', '')\n",
        "            object_types.add(object_name)\n",
        "\n",
        "    print(\"\\nPer-Object Classification Results:\")\n",
        "    print(\"==================================\")\n",
        "    for object_name in sorted(object_types):\n",
        "        object_data = []\n",
        "        object_labels = []\n",
        "        for person in range(1, 5):\n",
        "            for folder in range(1, 11):\n",
        "                file_path = os.path.join(base_path, str(person), FOLDER, str(folder), f'{object_name}_1.csv')\n",
        "                if os.path.exists(file_path):\n",
        "                    try:\n",
        "                        df = read_csv_file(file_path)\n",
        "                        if df is not None and not df.empty:\n",
        "                            features = extract_features(df)\n",
        "                            object_data.append(features)\n",
        "                            object_labels.append(person - 1)\n",
        "                    except Exception as e:\n",
        "                        continue\n",
        "        if object_data:\n",
        "            X_obj = np.array(object_data)\n",
        "            y_obj = np.array(object_labels)\n",
        "            print_classification_results(X_obj, y_obj, object_name)\n",
        "\n",
        "    # Visualize clusters using the three methods\n",
        "    print(\"\\nVisualizing clusters using t-SNE:\")\n",
        "    visualize_tsne_by_object(X, y, FILE_LIST, base_path)\n",
        "\n",
        "    print(\"\\nVisualizing clusters using PCA:\")\n",
        "    visualize_pca_by_object(X, y, FILE_LIST, base_path)\n",
        "\n",
        "    print(\"\\nVisualizing clusters using UMAP:\")\n",
        "    visualize_umap_by_object(X, y, FILE_LIST, base_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
